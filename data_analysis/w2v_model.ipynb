{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "import preprocessor_end\n",
    "import helper_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"C:/Users/Abdo/Project/data/subtitles/\"\n",
    "folders_names = os.listdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dictionary\n",
    "# has three keys (0_label, 1_label, no_label)\n",
    "# values are dictionaries that has as keys the names of files and as values the preprocessed corresponding file \n",
    "\n",
    "data_dictionary = {\n",
    "    \"0_label\":{},\n",
    "    \"1_label\":{},\n",
    "    \"no_label\":{}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for folder_name in folders_names:\n",
    "    dict = data_dictionary[folder_name]\n",
    "    files = os.listdir(folder_path+folder_name+\"/\")\n",
    "    for file in files:\n",
    "        if(file.endswith(\".srt\")):\n",
    "            dict[file] = preprocessor_end.preprocess_file(folder_path+folder_name+\"/\", file, False)\n",
    "        else:\n",
    "            dict[file] = preprocessor_end.preprocess_file(folder_path+folder_name+\"/\", file, True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('C:/Users/Abdo/Project/pickle_files/data_dictionary_before_removing_frequent_words.pkl', 'wb') as output:\n",
    "    #pickle.dump(data_dictionary, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('C:/Users/Abdo/Project/pickle_files/data_dictionary_before_removing_frequent_words.pkl','rb')\n",
    "data_dictionary = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the texts (arrays of words) combined in a single array (array of arrays)\n",
    "all_texts = []\n",
    "for label in data_dictionary.keys():\n",
    "    for file_name in data_dictionary[label].keys():\n",
    "        all_texts.append(data_dictionary[label][file_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "        all_texts,\n",
    "        size=150,\n",
    "        window=10,\n",
    "        min_count=5,\n",
    "        workers=10,iter=10,sample=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220806900, 222669120)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(all_texts, total_examples=len(all_texts), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('C:/Users/Abdo/Project/pickle_files/word2vec_model_trained_150.pkl', 'wb') as output:\n",
    "#pickle.dump(model, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('C:/Users/Abdo/Project/pickle_files/word2vec_model_trained_150.pkl','rb')\n",
    "model = pickle.load(pickle_in) # model trained on our data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = set(model.wv.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts the glove file to word2vec file, then load the word2vec model and returns it \n",
    "def glove_file_to_word2vec_model(glove_file_path):\n",
    "    glove_file = datapath(glove_file_path)\n",
    "    tmp_file = get_tmpfile(\"word2vec.txt\")\n",
    "    \n",
    "    # call glove2word2vec script\n",
    "    # default way (through CLI): python -m gensim.scripts.glove2word2vec --input <glove_file> --output <w2v_file>\n",
    "    glove2word2vec(glove_file, tmp_file)\n",
    "    return KeyedVectors.load_word2vec_format(tmp_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec_glove_model = glove_file_to_word2vec_model('C:/Users/Abdo/Project/glove.840B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('word2vec models/word2vecModel_glove_840b_300d.pkl', 'wb') as output:\n",
    "    #pickle.dump(word2vec_glove_model, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle_in = open('word2vec models/word2vecModel_glove_6b_200d.pkl','rb')\n",
    "#word2vec_glove_model = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the average, n dimensioned, vector embedding of every word in a given document\n",
    "# if a given word is not in the vocabulary of the model, it igonores it\n",
    "def average_word_vectors(words, model, vocabulary, num_features):\n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "    for word in words:\n",
    "        if word in vocabulary: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model[word])\n",
    "    \n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "        \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has two keys (0_label and 1_label) with a list of 150d vectors for each text\n",
    "featureVector_label_dictionary = {\"0_label\":[], \"1_label\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "for label in list(data_dictionary.keys())[0:2]:\n",
    "    for file_name in data_dictionary[label].keys():\n",
    "        text_feature_vector = average_word_vectors(data_dictionary[label][file_name], model, vocabulary, 150)\n",
    "        featureVector_label_dictionary[label].append(text_feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('C:/Users/Abdo/Project/pickle_files/featureVector_label_dictionary.pkl', 'wb') as output:\n",
    "    #pickle.dump(featureVector_label_dictionary, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('C:/Users/Abdo/Project/pickle_files/featureVector_label_dictionary.pkl','rb')\n",
    "featureVector_label_dictionary = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data in tuples : list of tuples : [(text_vector, label),.......]\n",
    "textVector_label_pairs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in featureVector_label_dictionary.keys():\n",
    "    for vector in featureVector_label_dictionary[label][0:1581]:\n",
    "        textVector_label_pairs.append((vector, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(textVector_label_pairs)\n",
    "shuffle(textVector_label_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for data_pair in textVector_label_pairs:\n",
    "    x.append(data_pair[0])\n",
    "    y.append(data_pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma=0.001,C=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x[:2000],y[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8098106712564543\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(x[2000:],y[2000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with open('C:/Users/Abdo/Project/pickle_files/svm_model.pkl', 'wb') as output:\n",
    "    #pickle.dump(clf, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle_in = open('C:/Users/Abdo/Project/pickle_files/svm_model.pkl','rb')\n",
    "#clf = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(word2vec_model, ml_model, vocabulary ,num_of_features, text_directory_path, text_name):\n",
    "    tokenized_text = preprocessor_end.preprocess_file(text_directory_path,text_name, True)\n",
    "    text_vector = average_word_vectors(tokenized_text, word2vec_model, vocabulary, num_of_features)\n",
    "    print( ml_model.predict([text_vector]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moana.2016.BDRip.x264-GECKOS + YTS.AG.srt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0_label']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "test_model(model, clf, vocabulary, 150, \"C:/Users/Abdo/Desktop/\",\"Moana.2016.BDRip.x264-GECKOS + YTS.AG.srt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

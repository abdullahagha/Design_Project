{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "from sklearn import svm, model_selection \n",
    "import data_analysis.preprocessor_end as pre_processer"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "Function defenitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_pickle(pickle_path, pick_name, variable_name):\n",
    "    with open(pickle_path + pick_name + \".pkl\", \"wb\") as pkl:\n",
    "        pickle.dump(variable_name, pkl)\n",
    "\n",
    "def in_pickle(pickle_path, pick_name):\n",
    "    with open(pickle_path + pick_name + \".pkl\", \"rb\") as pkl:\n",
    "        return pickle.load(pkl)\n",
    "\n",
    "# converts the glove file to word2vec file, then load the word2vec model and returns it \n",
    "def glove_file_to_word2vec_model(glove_file_path):\n",
    "    glove_file = datapath(glove_file_path)\n",
    "    tmp_file = get_tmpfile(\"word2vec.txt\")\n",
    "    \n",
    "    # call glove2word2vec script\n",
    "    # default way (through CLI): python -m gensim.scripts.glove2word2vec --input <glove_file> --output <w2v_file>\n",
    "    glove2word2vec(glove_file, tmp_file)\n",
    "    return KeyedVectors.load_word2vec_format(tmp_file)\n",
    "\n",
    "\n",
    "# returns the average, n dimensioned, vector embedding of every word in a given document\n",
    "# it sums all the vector values of every word in the document and then divides them by their count\n",
    "# if a given word is not in the vocabulary of the model, it ignores it\n",
    "def average_word_vectors(words, model, vocabulary, num_features):\n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "    for word in words:\n",
    "        if word in vocabulary: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model[word])\n",
    "    \n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "        \n",
    "    return feature_vector\n",
    "\n",
    "def average(lst): \n",
    "    return sum(lst) / len(lst) "
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "load the word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = in_pickle(\"C:/Users/Abdo/Project/pre-trained word2vec models-compiled/\",\n",
    "                               \"word2vecModel_glove_6b_300d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "vocabulary = set(word2vec_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "load the data frames, the label_documentVector_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_frames = pro.in_pickle(\"C:/Users/Abdo/Project/pickle_files/\",\"pandas_data_frame\")\n",
    "label_documentVector_dictionary = in_pickle(\"C:/Users/Abdo/Project/pickle_files/12_21_31/\",\n",
    "                                                \"label_documentVector_dictionary_12_21_31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key : label\n",
    "# value: [ (doc_name, doc_vector_presentation), ......  ]\n",
    "label_documentVector_dictionary = {\"0_label\": [], \"1_label\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data_frames.iterrows():\n",
    "    movie_id = row[\"movie_id\"]\n",
    "    rating = row[\"rating\"]\n",
    "    movie_words = row[\"movie_words\"]\n",
    "    \n",
    "    doc_vector = average_word_vectors(movie_words, word2vec_model, vocabulary, 300)\n",
    "    label_documentVector_dictionary[rating].append((movie_id, doc_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pickle(\"C:/Users/Abdo/Project/pickle_files/13_21_31/\",\n",
    "               \"label_documentVector_dictionary_13_21_31\", label_documentVector_dictionary)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "done getting documents' vector presentation\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "put the (doc_vector, doc_label) pairs in proper shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ (doc_vector, label), .....  ]\n",
    "# it has equal number of 0_label 1_label samples\n",
    "doc_vector_label_pairs = []"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "create a list which has an equal number of 0_label and 1_label samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for movie_info in (label_documentVector_dictionary[\"0_label\"]):\n",
    "    movie_vector = movie_info[1]\n",
    "    doc_vector_label_pairs.append((movie_vector, \"0_label\")) \n",
    "\n",
    "for movie_info in (label_documentVector_dictionary[\"1_label\"]):\n",
    "    movie_vector = movie_info[1]\n",
    "    doc_vector_label_pairs.append((movie_vector, \"1_label\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the array to randomly distribute the 0_label 1_label inside it\n",
    "shuffle(doc_vector_label_pairs)\n",
    "shuffle(doc_vector_label_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for data_pair in doc_vector_label_pairs:\n",
    "    x.append(data_pair[0])\n",
    "    y.append(data_pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the labeling -> 0_label : 1,  1_label : 0\n",
    "\n",
    "# 0 data is 75%\n",
    "# 1 data is 25%\n",
    "inverse_labeled_y = []\n",
    "for element in y:\n",
    "    if element == \"0_label\":\n",
    "        inverse_labeled_y.append(1)\n",
    "    else:\n",
    "        inverse_labeled_y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_percentage = 0.7\n",
    "training_data_size = int(len(x) * training_data_percentage)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 6,
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate \n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key: kernel-c-gamma\n",
    "# value : (corresponding SVM classifier, result_dict)\n",
    "#   result_dict -> key:scoring type, value: scoring value\n",
    "svm_classifiers_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = [\"poly\", \"rbf\", \"sigmoid\",\"linear\"]\n",
    "c_values_1 = [0.001, 1, 5] # common between all kernels\n",
    "gamma_values_1 = [0.001, 1, 5] # for rbf, sigmoid, poly\n",
    "\n",
    "#c_values_2 = [0.0001, 2, 5, 10] # common between all kernels\n",
    "#gamma_values_2 = [0.0001, 2, 5, 10] # for rbf, sigmoid, poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the given classifier using cross validation with different scorings\n",
    "# return the result as a dictionary\n",
    "# keys: 'accuracy', 'precision', 'recall', 'f1_score', 'confusion_matrix' \n",
    "# which store metrics values on each fold for certain metric.\n",
    "def test_classifier(clf, x, y, scoring):\n",
    "    results = model_selection.cross_validate(estimator=clf, X=x, y=y, cv=10, scoring=scoring)\n",
    "    return results\n",
    "\n",
    "# makes an SVM classifier using every possible combination of these parameters\n",
    "# it then tests every classifier using K-fold cross validation\n",
    "# then, it adds the results(precision, recall, accuracy, ....) to svm_classifiers_dict\n",
    "# it then pickles out the svm_classifiers_dict\n",
    "def get_svm_classifiers(kernel, gamma_values, c_values ,svm_classifiers_dict, x, y, scoring):\n",
    "    if kernel == \"linear\":\n",
    "        for c in c_values:\n",
    "            clf = svm.SVC(kernel=kernel, C=c)\n",
    "            results = test_classifier(clf, x, y, scoring)\n",
    "            svm_classifiers_dict[kernel+\"-\"+str(c)] = (clf, results) \n",
    "    else:\n",
    "        for c in c_values:\n",
    "            for gamma in gamma_values:\n",
    "                clf = svm.SVC(kernel=kernel, C=c, gamma=gamma)\n",
    "                results = test_classifier(clf, x, y, scoring)\n",
    "                svm_classifiers_dict[kernel+\"-\"+str(c)+\"-\"+str(gamma)] = (clf, results)\n",
    "    \n",
    "    #pickle out the svm_classifiers_dict\n",
    "    out_pickle(\"C:/Users/Abdo/Project/pickle_files/13_21_31/\",\"svm_classifiers_dict\", svm_classifiers_dict)\n",
    "\n",
    "# utf8: true if the file is a .txt file, false otherwise\n",
    "def test_classifier_on_outside_data(classifer, directory_path, txt_file_name, utf8):\n",
    "    txt_data_tokens = pre_processer.preprocess_file(directory_path, txt_file_name, utf8)\n",
    "    #print(txt_data_tokens)\n",
    "    text_vector_representation = average_word_vectors(txt_data_tokens, word2vec_model, vocabulary, 300)\n",
    "    \n",
    "    prediction = classifer.predict([text_vector_representation])\n",
    "    \n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm_classifiers_dict = pro.in_pickle(\"C:/Users/Abdo/Project/pickle_files/11_21_31/\",\"svm_classifiers_dict\")"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "load the trained svm classier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = in_pickle(\"C:/Users/Abdo/Project/pickle_files/\",\"svm_final_classifier\")"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "test a desierd classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = svm.SVC(kernel=\"rbf\", gamma=5, C=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf_results = test_classifier(clf, x, inverse_labeled_y, scoring)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "Train the classifer ( fit it )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=5, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma=5, kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf.fit(x, inverse_labeled_y)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "test the classifer on data we provide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_label-6.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "prediction = test_classifier_on_outside_data(clf, \"C:/Users/Abdo/Project/test_data/\",\"0_label-6.txt\", True)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pickle(\"C:/Users/Abdo/Project/pickle_files/\",\"svm_final_classifier\", clf)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "test the linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get_svm_classifiers(\"linear\", gamma_values_1, c_values_1, svm_classifiers_dict, x, inverse_labeled_y, scoring)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "test the poly kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_svm_classifiers(\"poly\", gamma_values_1, c_values_1, svm_classifiers_dict, x, inverse_labeled_y, scoring)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "test the rbf kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_svm_classifiers(\"rbf\", gamma_values_1, c_values_1, svm_classifiers_dict, x, inverse_labeled_y, scoring)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "test the sigmoid kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#get_svm_classifiers(\"sigmoid\", gamma_values_1, c_values_1, svm_classifiers_dict, x, inverse_labeled_y, scoring)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "create a dict that has all data frames from the three word2vec moodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key: name of word2vec model\n",
    "# value: corresponding data frame\n",
    "classifiers_results_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_models_paths = [\"11_21_31\", \"12_21_31\", \"13_21_31\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n  warnings.warn(*warn_args, **warn_kwargs)\nC:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n  warnings.warn(*warn_args, **warn_kwargs)\nC:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n  warnings.warn(*warn_args, **warn_kwargs)\nC:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "for word2vec_model_path in word2vec_models_paths:\n",
    "    svm_classifiers_dict = pro.in_pickle(\"C:/Users/Abdo/Project/pickle_files/\"+word2vec_model_path+\"/\",\"svm_classifiers_dict\")\n",
    "    \n",
    "    # key: classifier, test_accuracy, train_accuracy, .....\n",
    "    # value: [ row1_value, row2_value,  ]\n",
    "    pandas_dict_svm_classifiers = {}\n",
    "    \n",
    "    # initialize the values of the svm_classifiers_dict\n",
    "    # end up with pandas_dict_svm_classifiers having keys of (classifier, test_accuracy, .....)\n",
    "    pandas_dict_svm_classifiers[\"classifier\"] = []\n",
    "    for classifier in svm_classifiers_dict.keys():\n",
    "        list_of_folds_results = svm_classifiers_dict[classifier][1]\n",
    "        for result in list_of_folds_results:\n",
    "            pandas_dict_svm_classifiers[result] = []\n",
    "   \n",
    "    # take the average value from the 10 folds for each score in every classifier\n",
    "    for classifier in svm_classifiers_dict.keys():\n",
    "        # the name of the current svm classifier (linear-1-1 for example)\n",
    "        pandas_dict_svm_classifiers[\"classifier\"].append(classifier)\n",
    "        # its results (test_accuracy, .....)\n",
    "        dict_of_folds_results = svm_classifiers_dict[classifier][1]\n",
    "        # for each one of them \n",
    "        for result in dict_of_folds_results:\n",
    "            # append its average, because its 10 value one for each fold, to the corresponding key's list\n",
    "            pandas_dict_svm_classifiers[result].append( average(dict_of_folds_results[result]) )\n",
    "    \n",
    "    # turn the dictionary into a pandas data frame\n",
    "    classifiers_results_data_frame = pd.DataFrame(pandas_dict_svm_classifiers)\n",
    "    # drop out its fit_time, score_time columns\n",
    "    classifiers_results_data_frame.drop(\"fit_time\", 1, inplace=True)\n",
    "    classifiers_results_data_frame.drop(\"score_time\", 1, inplace=True)\n",
    "    \n",
    "    classifiers_results_dict[word2vec_model_path] = classifiers_results_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_pickle(\"C:/Users/Abdo/Project/pickle_files/\",\"classifiers_results_dict\", classifiers_results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_results_dict = pro.in_pickle(\"C:/Users/Abdo/Project/pickle_files/\",\"classifiers_results_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_results_panda_frames_dict = pro.in_pickle(\"C:/Users/Abdo/Project/pickle_files/\",\"classifiers_results_panda_frames_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key : word2vec model name (example: 11_21_31)\n",
    "# value: dict\n",
    "#        key: kernel name (linear, rbf, ...)\n",
    "#        value: data frame (c_gamma, test_accuracy, .....)\n",
    "classifiers_results_panda_frames_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key: test_accuracy, ....\n",
    "# value: [ row1, row2, ....]\n",
    "# this is meant to be used by the pandas to make data frames of its shape\n",
    "pandas_dict_svm_classifiers = {}\n",
    "for classifier in svm_classifiers_dict.keys():\n",
    "    list_of_folds_results = svm_classifiers_dict[classifier][1]\n",
    "    # skip the time scores\n",
    "    for result in list(list_of_folds_results.keys())[2:]:\n",
    "        pandas_dict_svm_classifiers[result] = []\n",
    "    # add a key for the c and gamma values\n",
    "    pandas_dict_svm_classifiers[\"c\"] = []\n",
    "    pandas_dict_svm_classifiers[\"gamma\"] = []"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "initilize the values of classifiers_results_panda_frames_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word2vec_model_name in word2vec_models_paths:\n",
    "    classifiers_results_panda_frames_dict[word2vec_model_name] = {}\n",
    "\n",
    "for word2vec_model_name in word2vec_models_paths:\n",
    "    for kernel in kernels:\n",
    "        classifiers_results_panda_frames_dict[word2vec_model_name][kernel] = pd.DataFrame(pandas_dict_svm_classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each word2vec model (11_21_31, ...)\n",
    "for word2vec_model_name in classifiers_results_dict:\n",
    "    \n",
    "    # for each row in that model's data frame\n",
    "    for index, row in classifiers_results_dict[word2vec_model_name].iterrows():\n",
    "        # elements to it should added in this order:\n",
    "        # test_accuracy, train_accuracy, test_precision, train_precision, test_recall, train_recall, test_f1_score, train_f1_score, c, gamma\n",
    "        list_to_be_added_to_data_frame = []\n",
    "        kernel_name = row[\"classifier\"].split(\"-\")[0]\n",
    "        c = row[\"classifier\"].split(\"-\")[1]\n",
    "        gamma = 0\n",
    "        if (kernel_name != \"linear\"):\n",
    "            gamma = row[\"classifier\"].split(\"-\")[2]\n",
    "        \n",
    "        list_to_be_added_to_data_frame.append(row[\"test_accuracy\"])\n",
    "        list_to_be_added_to_data_frame.append(row[\"train_accuracy\"])\n",
    "        list_to_be_added_to_data_frame.append(row[\"test_precision\"])\n",
    "        list_to_be_added_to_data_frame.append(row[\"train_precision\"])\n",
    "        list_to_be_added_to_data_frame.append(row[\"test_recall\"])\n",
    "        list_to_be_added_to_data_frame.append(row[\"train_recall\"])\n",
    "        list_to_be_added_to_data_frame.append(row[\"test_f1_score\"])\n",
    "        list_to_be_added_to_data_frame.append(row[\"train_f1_score\"])\n",
    "        list_to_be_added_to_data_frame.append(c)\n",
    "        list_to_be_added_to_data_frame.append(gamma)\n",
    "        \n",
    "        # get the data frame corresponding with the word2vec model and kernel \n",
    "        df = classifiers_results_panda_frames_dict[word2vec_model_name][kernel_name]\n",
    "        df.loc[index] = list_to_be_added_to_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pickle(\"C:/Users/Abdo/Project/pickle_files/\",\"classifiers_results_panda_frames_dict\", classifiers_results_panda_frames_dict)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "remove some un-necessary data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the train_accuracy, train_precision, train_recall, train_f1_score columns\n",
    "for word2vec_model in classifiers_results_panda_frames_dict:\n",
    "    for kernel in classifiers_results_panda_frames_dict[word2vec_model]:\n",
    "        classifiers_results_panda_frames_dict[word2vec_model][kernel].drop(\n",
    "            [\"train_accuracy\",\"train_precision\", \"train_recall\", \"train_f1_score\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "create a new column in the data frame called averaged_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the average test_accuracy, test_precision, test_recall and put the value in a new column called averaged_value\n",
    "for word2vec_model in classifiers_results_panda_frames_dict:\n",
    "    # for each kernel\n",
    "    for kernel in classifiers_results_panda_frames_dict[word2vec_model]:\n",
    "        # create the new column array\n",
    "        averaged_values = []\n",
    "\n",
    "        # for each row in that model's data frame, find the averaged value of (test_accuracy, test_precision, test_recall)\n",
    "        # add it to the averaged_values list\n",
    "        for index, row in classifiers_results_panda_frames_dict[word2vec_model][kernel].iterrows():\n",
    "            averaged_value = (row[\"test_accuracy\"] + row[\"test_precision\"] + row[\"test_recall\"]) /3\n",
    "            averaged_values.append(averaged_value)\n",
    "        # add the new column\n",
    "        classifiers_results_panda_frames_dict[word2vec_model][kernel][\"averaged_values\"] = averaged_values"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "statistical study about the classifiers results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the data frames with respect to the averaged_values\n",
    "# take the average test_accuracy, test_precision, test_recall and put the value in a new column called averaged_value\n",
    "for word2vec_model in classifiers_results_panda_frames_dict:\n",
    "    # for each kernel\n",
    "    for kernel in classifiers_results_panda_frames_dict[word2vec_model]:\n",
    "        classifiers_results_panda_frames_dict[word2vec_model][kernel].sort_values(\"averaged_values\", inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_neighbors':[5,10],\n",
    "          'leaf_size':[1,5],\n",
    "          'weights':['uniform', 'distance'],\n",
    "          'algorithm':['auto', 'ball_tree','kd_tree','brute']}"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "create a KNN classifier for each combination of params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key: classifier_name (algorithm-n_neighbors-leaf_size-weights)\n",
    "# value: (classifier, results)\n",
    "\n",
    "knn_classifiers_results_dict = {}\n",
    "\n",
    "for n_neighbors in params[\"n_neighbors\"]:\n",
    "    for leaf_size in params[\"leaf_size\"]:\n",
    "        for weight in params[\"weights\"]:\n",
    "            for algorithm in params[\"algorithm\"]:\n",
    "                # create the classifier\n",
    "                classifier = KNeighborsClassifier(n_jobs=-1, n_neighbors=n_neighbors, leaf_size=leaf_size, weights=weight, algorithm=algorithm)\n",
    "                # name of it: algorithm-n_neighbors-leaf_size-weights\n",
    "                classifier_name = str(algorithm)+\"-\"+str(n_neighbors)+\"-\"+str(leaf_size)+\"-\"+str(weight)\n",
    "                # get the cross validated results for each classifier\n",
    "                results = test_classifier(classifier, x, inverse_labeled_y, scoring)\n",
    "                # add the values to the knn_classifiers_results_dict \n",
    "                knn_classifiers_results_dict[classifier_name] = (classifier, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_pickle(\"C:/Users/Abdo/Project/pickle_files/\",\"knn_classifiers_results_dict\", knn_classifiers_results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifiers_results_dict = pro.in_pickle(\"C:/Users/Abdo/Project/pickle_files/\",\"knn_classifiers_results_dict\")"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "make a pandas data frame to hold the knn results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key: test_accuracy, .... (columns)\n",
    "# value: [ row1, row2, ....]  (rows)\n",
    "knn_classifiers_results_panda_frames_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the values in pandas_columns\n",
    "for score_type in list(knn_classifiers_results_dict[\"ball_tree-5-1-uniform\"][1].keys()):\n",
    "    knn_classifiers_results_panda_frames_dict[score_type] = [] # test_accuracy, ....\n",
    "\n",
    "knn_classifiers_results_panda_frames_dict[\"n\"] = []\n",
    "knn_classifiers_results_panda_frames_dict[\"leaf\"] = []\n",
    "knn_classifiers_results_panda_frames_dict[\"weights\"] = []\n",
    "knn_classifiers_results_panda_frames_dict[\"algorithm\"] = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n  warnings.warn(*warn_args, **warn_kwargs)\nC:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n  warnings.warn(*warn_args, **warn_kwargs)\nC:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n  warnings.warn(*warn_args, **warn_kwargs)\nC:\\Users\\Abdo\\PycharmProjects\\final_project_1\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_f1_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "for knn_classifier in knn_classifiers_results_dict:\n",
    "    # add the values to each column, each iteration correspond to a row\n",
    "    knn_classifiers_results_panda_frames_dict[\"n\"].append(knn_classifier.split(\"-\")[1])\n",
    "    knn_classifiers_results_panda_frames_dict[\"algorithm\"].append(knn_classifier.split(\"-\")[0])\n",
    "    knn_classifiers_results_panda_frames_dict[\"leaf\"].append(knn_classifier.split(\"-\")[2])\n",
    "    knn_classifiers_results_panda_frames_dict[\"weights\"].append(knn_classifier.split(\"-\")[3])\n",
    "    # test_accuracy, .....\n",
    "    for score_type in list(knn_classifiers_results_dict[\"ball_tree-5-1-uniform\"][1].keys()):\n",
    "        knn_classifiers_results_panda_frames_dict[score_type].append(average(knn_classifiers_results_dict[knn_classifier][1][score_type]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifiers_results_panda_frames = pd.DataFrame(knn_classifiers_results_panda_frames_dict)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "remove some un-necessary elements from the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifiers_results_panda_frames.drop(\"fit_time\",1, inplace=True)\n",
    "knn_classifiers_results_panda_frames.drop(\"score_time\",1, inplace=True)\n",
    "knn_classifiers_results_panda_frames.drop(\"train_accuracy\",1, inplace=True)\n",
    "knn_classifiers_results_panda_frames.drop(\"train_precision\",1, inplace=True)\n",
    "knn_classifiers_results_panda_frames.drop(\"train_recall\",1, inplace=True)\n",
    "knn_classifiers_results_panda_frames.drop(\"train_f1_score\",1, inplace=True)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    " add the average values columns (test_accuracy + test_precicison + test_recall)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_values = []\n",
    "# for each row in that model's data frame, find the averaged value of (test_accuracy, test_precision, test_recall)\n",
    "# add it to the averaged_values list\n",
    "for index, row in knn_classifiers_results_panda_frames.iterrows():\n",
    "    averaged_value = (row[\"test_accuracy\"] + row[\"test_precision\"] + row[\"test_recall\"]) /3\n",
    "    averaged_values.append(averaged_value)\n",
    "    # add the new column\n",
    "knn_classifiers_results_panda_frames[\"averaged_values\"] = averaged_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifiers_results_panda_frames.sort_values(\"averaged_values\", inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model\n",
    "def create_baseline():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(300, input_dim=300, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "normalized_x = keras.utils.normalize(x, axis=-1, order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 80.42% (2.70%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, np.array(x), inverse_labeled_y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
